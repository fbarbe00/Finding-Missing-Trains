{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22502/22502 [00:07<00:00, 2887.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load station data\n",
    "stations_df = pd.read_csv(\n",
    "    \"../../data/trainline/stations.csv\",\n",
    "    sep=\";\",\n",
    "    usecols=[\"name\", \"latitude\", \"longitude\", \"uic\", \"country\"],\n",
    ").dropna().reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "# Load city population data\n",
    "population_df = pd.read_csv(\"population_cities_europe_latest_coordinates.csv\")\n",
    "\n",
    "# Convert degrees to radians for both datasets\n",
    "stations_df[[\"latitude\", \"longitude\"]] = np.radians(stations_df[[\"latitude\", \"longitude\"]])\n",
    "population_df[[\"latitude\", \"longitude\"]] = np.radians(population_df[[\"latitude\", \"longitude\"]])\n",
    "\n",
    "# Earth's radius in kilometers\n",
    "EARTH_RADIUS_KM = 6371  \n",
    "\n",
    "# Convert latitude/longitude into 3D Cartesian coordinates for KDTree\n",
    "def latlon_to_cartesian(lat, lon):\n",
    "    \"\"\"Convert latitude/longitude in radians to Cartesian coordinates.\"\"\"\n",
    "    x = np.cos(lat) * np.cos(lon)\n",
    "    y = np.cos(lat) * np.sin(lon)\n",
    "    z = np.sin(lat)\n",
    "    return np.column_stack((x, y, z))\n",
    "\n",
    "# Create a KDTree in 3D space\n",
    "population_tree = cKDTree(latlon_to_cartesian(\n",
    "    population_df[\"latitude\"].values, population_df[\"longitude\"].values\n",
    "))\n",
    "\n",
    "# Function to find the closest city using Haversine distance\n",
    "def find_closest_city(station):\n",
    "    \"\"\"Find the nearest city to a station using KDTree in 3D space.\"\"\"\n",
    "    lat, lon = station[\"latitude\"], station[\"longitude\"]\n",
    "    \n",
    "    # Convert station lat/lon to Cartesian coordinates\n",
    "    station_xyz = latlon_to_cartesian(lat, lon)[0]\n",
    "    \n",
    "    # Query KDTree\n",
    "    dist_idx = population_tree.query(station_xyz, k=1)\n",
    "    \n",
    "    # Retrieve population and haversine distance\n",
    "    city_idx = dist_idx[1]\n",
    "    closest_city = population_df.iloc[city_idx]\n",
    "    \n",
    "    # Compute actual Haversine distance\n",
    "    dlat = closest_city[\"latitude\"] - lat\n",
    "    dlon = closest_city[\"longitude\"] - lon\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat) * np.cos(closest_city[\"latitude\"]) * np.sin(dlon / 2) ** 2\n",
    "    haversine_dist = 2 * EARTH_RADIUS_KM * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    return pd.Series([closest_city[\"population\"], city_idx, haversine_dist])\n",
    "\n",
    "# Apply the function to all stations\n",
    "tqdm.pandas()\n",
    "stations_df[[\"population\", \"closest_city_id\", \"distance_km\"]] = stations_df.progress_apply(\n",
    "    find_closest_city, axis=1\n",
    ")\n",
    "\n",
    "stations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'int64', 'name': 'object', 'uic': 'float64', 'latitude': 'float64', 'longitude': 'float64', 'country': 'object', 'population': 'float64', 'closest_city_id': 'float64', 'distance_km': 'float64'}\n"
     ]
    }
   ],
   "source": [
    "# print dtypes as dict\n",
    "dtypes_dict = stations_df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "print(dtypes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:07<00:00,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking by Simple Efficiency Score:\n",
      "                             simple\n",
      "station_name                       \n",
      "Bruxelles-Midi         69413.396551\n",
      "Paris Gare du Nord     60684.553531\n",
      "Amsterdam-Centraal     41413.237897\n",
      "Luxembourg – Gare      32628.762731\n",
      "Berlin Hbf             29687.210385\n",
      "Praha hl.n.            22486.372949\n",
      "Wien Hbf               22280.557419\n",
      "København              15969.132458\n",
      "Bratislava hl.st.      14302.895431\n",
      "Madrid Atocha          13275.749666\n",
      "Budapest-Keleti        13189.696588\n",
      "Warszawa-Wschodnia     11420.261293\n",
      "Stockholm Central       7015.550881\n",
      "Zagreb                  6451.658138\n",
      "Roma Termini            5306.098930\n",
      "Vilnius                 2965.349174\n",
      "Lisboa Santa Apolónia   1908.087723\n",
      "Riga                    1709.857827\n",
      "Helsinki asema           151.603981\n",
      "București Nord            12.050744\n",
      "Athens                     0.000000\n",
      "Ljubljana                  0.000000\n",
      "\n",
      "Ranking by Distance-Adjusted Efficiency Score:\n",
      "                       distance_adjusted\n",
      "station_name                            \n",
      "Bruxelles-Midi             666023.732231\n",
      "Paris Gare du Nord         588433.598939\n",
      "Amsterdam-Centraal         480233.573048\n",
      "Berlin Hbf                 425822.816994\n",
      "Wien Hbf                   411420.097328\n",
      "Luxembourg – Gare          381002.910709\n",
      "Budapest-Keleti            313982.470876\n",
      "Warszawa-Wschodnia         284589.592091\n",
      "Praha hl.n.                269545.029922\n",
      "Madrid Atocha              264138.066738\n",
      "Bratislava hl.st.          262004.306643\n",
      "København                  228878.195679\n",
      "Stockholm Central          194842.405400\n",
      "Zagreb                     151474.357182\n",
      "Roma Termini               108163.365584\n",
      "Vilnius                     86707.034749\n",
      "Riga                        59756.648224\n",
      "Lisboa Santa Apolónia       48504.577182\n",
      "Helsinki asema               1152.858354\n",
      "București Nord                111.284660\n",
      "Athens                          0.000000\n",
      "Ljubljana                       0.000000\n",
      "\n",
      "Ranking by Normalized Composite Score:\n",
      "                       normalized\n",
      "station_name                     \n",
      "Bruxelles-Midi           0.140571\n",
      "Paris Gare du Nord       0.124521\n",
      "Warszawa-Wschodnia       0.119807\n",
      "Berlin Hbf               0.118237\n",
      "Wien Hbf                 0.111974\n",
      "Amsterdam-Centraal       0.105270\n",
      "Budapest-Keleti          0.103352\n",
      "Luxembourg – Gare        0.100990\n",
      "Bratislava hl.st.        0.097554\n",
      "Madrid Atocha            0.092629\n",
      "Praha hl.n.              0.090966\n",
      "København                0.083602\n",
      "Stockholm Central        0.079013\n",
      "Zagreb                   0.066921\n",
      "Roma Termini             0.053308\n",
      "Vilnius                  0.034631\n",
      "Riga                     0.033127\n",
      "Lisboa Santa Apolónia    0.031398\n",
      "Helsinki asema           0.000109\n",
      "București Nord           0.000007\n",
      "Athens                   0.000000\n",
      "Ljubljana                0.000000\n",
      "\n",
      "Ranking by Normalized Composite Ratio Score (Country Population Proportion):\n",
      "                       normalized_ratio\n",
      "station_name                           \n",
      "Paris Gare du Nord            12.284902\n",
      "Berlin Hbf                     9.958704\n",
      "Bruxelles-Midi                 9.910070\n",
      "Amsterdam-Centraal             9.348768\n",
      "Warszawa-Wschodnia             9.069457\n",
      "Madrid Atocha                  8.474656\n",
      "Wien Hbf                       8.454850\n",
      "Luxembourg – Gare              8.406121\n",
      "København                      7.926671\n",
      "Bratislava hl.st.              7.765841\n",
      "Praha hl.n.                    7.753300\n",
      "Stockholm Central              7.628496\n",
      "Budapest-Keleti                7.028028\n",
      "Vilnius                        5.187159\n",
      "Zagreb                         4.911437\n",
      "Roma Termini                   4.450317\n",
      "Riga                           2.891160\n",
      "Lisboa Santa Apolónia          2.789726\n",
      "Helsinki asema                 0.530617\n",
      "București Nord                 0.439357\n",
      "Athens                         0.000000\n",
      "Ljubljana                      0.000000\n",
      "\n",
      "Ranking by Normalized Composite Rank Score (Country Population Rank):\n",
      "                       normalized_rank\n",
      "station_name                          \n",
      "Paris Gare du Nord            4.467148\n",
      "Warszawa-Wschodnia            4.036787\n",
      "Berlin Hbf                    4.010407\n",
      "Bruxelles-Midi                3.881567\n",
      "Wien Hbf                      3.814243\n",
      "Madrid Atocha                 3.458482\n",
      "Budapest-Keleti               3.428175\n",
      "Amsterdam-Centraal            3.340084\n",
      "Bratislava hl.st.             3.247820\n",
      "Praha hl.n.                   2.872065\n",
      "Stockholm Central             2.845907\n",
      "Luxembourg – Gare             2.795716\n",
      "København                     2.759400\n",
      "Zagreb                        2.155753\n",
      "Vilnius                       1.948602\n",
      "Roma Termini                  1.727483\n",
      "Lisboa Santa Apolónia         1.210361\n",
      "Riga                          1.076020\n",
      "Helsinki asema                0.021046\n",
      "București Nord                0.001010\n",
      "Athens                        0.000000\n",
      "Ljubljana                     0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Haversine formula to calculate the distance between two points (in kilometers).\"\"\"\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def filter_stations(merged, min_distance_km, max_station_distance_km):\n",
    "    \"\"\"Filter merged DataFrame by a minimum computed distance and a maximum station-defined distance.\"\"\"\n",
    "    if min_distance_km is not None:\n",
    "        merged = merged[merged['distance'] >= min_distance_km]\n",
    "    if max_station_distance_km is not None:\n",
    "        merged = merged[merged['distance_km'] <= max_station_distance_km]\n",
    "    return merged\n",
    "\n",
    "def prepare_merged_df(travel_df, stations_df, starting_station, min_distance_km, max_station_distance_km):\n",
    "    \"\"\"\n",
    "    Prepares a merged DataFrame by:\n",
    "      - Keeping only the fastest connection for each destination.\n",
    "      - Merging with station data.\n",
    "      - Computing the geographical distance from the starting station.\n",
    "      - Applying distance filters.\n",
    "    \"\"\"\n",
    "    # Keep only the fastest connection per destination station\n",
    "    travel_df = travel_df.sort_values('duration_seconds').groupby('destination_station_id', as_index=False).first()\n",
    "    merged = pd.merge(travel_df, stations_df, left_on='destination_station_id', right_on='id', how='left')\n",
    "    \n",
    "    # Compute the distance from the starting station to each destination\n",
    "    lat0, lon0 = starting_station['latitude'], starting_station['longitude']\n",
    "    merged['distance'] = merged.apply(lambda row: compute_haversine(lat0, lon0, row['latitude'], row['longitude']), axis=1)\n",
    "    \n",
    "    # Apply the distance filters\n",
    "    merged = filter_stations(merged, min_distance_km, max_station_distance_km)\n",
    "    \n",
    "    # Avoid division by zero if distance is zero\n",
    "    merged['distance'] = merged['distance'].replace(0, 0.001)\n",
    "    # Convert duration from seconds to hours for scoring functions if needed\n",
    "    merged['duration'] = merged['duration_seconds'] / 3600.0\n",
    "    return merged\n",
    "\n",
    "def simple_efficiency_score(merged):\n",
    "    \"\"\"\n",
    "    Simple Efficiency Score:\n",
    "    Score = sum( population / (duration * (transfers + 1)) )\n",
    "    \"\"\"\n",
    "    merged['score_component'] = merged['population'] / (merged['duration'] * (merged['transfers'] + 1))\n",
    "    return merged['score_component'].sum()\n",
    "\n",
    "def distance_adjusted_score(merged):\n",
    "    \"\"\"\n",
    "    Distance-Adjusted Efficiency Score:\n",
    "    Score = sum( (population * distance) / (duration * (transfers + 1)) )\n",
    "    \"\"\"\n",
    "    merged['score_component'] = (merged['population'] * merged['distance']) / (merged['duration'] * (merged['transfers'] + 1))\n",
    "    return merged['score_component'].sum()\n",
    "\n",
    "def exponential_decay_score(merged, lambda_T=0.001, lambda_k=1, lambda_d=0.1):\n",
    "    \"\"\"\n",
    "    Exponential Decay Score:\n",
    "    Score = sum( population * exp(-lambda_T * duration) * exp(-lambda_k * transfers) * exp(-lambda_d * distance) )\n",
    "    \"\"\"\n",
    "    merged['score_component'] = merged['population'] * \\\n",
    "                                np.exp(-lambda_T * merged['duration']) * \\\n",
    "                                np.exp(-lambda_k * merged['transfers']) * \\\n",
    "                                np.exp(-lambda_d * merged['distance'])\n",
    "    return merged['score_component'].sum()\n",
    "\n",
    "def normalized_composite_score(merged, stations_df, alpha=1.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    Normalized Composite Score:\n",
    "    Score = sum( (normalized_population) / (1 + alpha*(duration/distance) + beta*transfers) )\n",
    "    where normalized_population = population / max(population)\n",
    "    \"\"\"\n",
    "    max_population = stations_df['population'].max()\n",
    "    merged['normalized_population'] = merged['population'] / max_population\n",
    "    merged['score_component'] = merged['normalized_population'] / (\n",
    "                                  1 + alpha * (merged['duration'] / merged['distance']) + beta * merged['transfers'])\n",
    "    return merged['score_component'].sum()\n",
    "\n",
    "def normalized_composite_ratio_score(merged, alpha=1.0, beta=1.0, scaling_factor=1000):\n",
    "    \"\"\"\n",
    "    Normalized Composite Ratio Score:\n",
    "    For each destination station, compute the ratio of its population to the total population\n",
    "    of its country. Then use this ratio in the composite score, scaled by a constant factor.\n",
    "    \n",
    "    For a destination j in country C:\n",
    "       R_j = (population_j / total population of C) * scaling_factor\n",
    "    \n",
    "    Score = sum( R_j / (1 + alpha*(duration/distance) + beta*transfers) )\n",
    "    \"\"\"\n",
    "    # First, compute total population per country\n",
    "    country_totals = merged.groupby('country')['population'].transform('sum')\n",
    "    merged['population_ratio'] = (merged['population'] / country_totals) * scaling_factor\n",
    "    merged['score_component'] = merged['population_ratio'] / (\n",
    "                                  1 + alpha * (merged['duration'] / merged['distance']) + beta * merged['transfers'])\n",
    "    return merged['score_component'].sum()\n",
    "\n",
    "def normalized_composite_rank_score(merged, stations_df, alpha=1.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    Normalized Composite Rank Score:\n",
    "    Instead of the actual population, use a rank-based measure. For each destination station,\n",
    "    compute its population rank within its country and convert that into a normalized rank score.\n",
    "    \n",
    "    For a destination station j in country C:\n",
    "       Let r_j be its rank among stations in C (1 = highest population) and N be the number of stations in C.\n",
    "       Define R*_j = (N - r_j + 1) / N.\n",
    "    \n",
    "    Score = sum( R*_j / (1 + alpha*(duration/distance) + beta*transfers) )\n",
    "    \"\"\"\n",
    "    merged_copy = merged.copy()\n",
    "    merged_copy['rank'] = merged_copy.groupby('country')['population'].rank(method='min', ascending=False)\n",
    "    counts = merged_copy.groupby('country')['population'].transform('count')\n",
    "    merged_copy['rank_norm'] = (counts - merged_copy['rank'] + 1) / counts\n",
    "    merged_copy['score_component'] = merged_copy['rank_norm'] / (\n",
    "                                       1 + alpha * (merged_copy['duration'] / merged_copy['distance']) + beta * merged_copy['transfers'])\n",
    "    return merged_copy['score_component'].sum()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Parameters for filtering and scoring\n",
    "MIN_DISTANCE_KM = 5      # Exclude connections with distance less than 5 km\n",
    "MAX_STATION_DISTANCE_KM = 100  # Ignore stations with a \"distance_km\" value > 100\n",
    "\n",
    "# Parameters for composite scores\n",
    "ALPHA = 1.0\n",
    "BETA = 1.0\n",
    "\n",
    "# Dictionary to store scores for each starting station\n",
    "scores_dict = {}\n",
    "\n",
    "# Loop through each CSV file in the \"travel_times\" folder\n",
    "input_folder = \"travel_times_output\"\n",
    "input_files = [file for file in os.listdir(input_folder) if file.startswith('motis_from_') and file.endswith('.csv')]\n",
    "\n",
    "for file in tqdm(input_files):\n",
    "    travel_df = pd.read_csv(os.path.join(input_folder, file))\n",
    "    # Assuming filename format: motis_from_startStationId_timestamp_method.csv\n",
    "    parts = file.split(\"_\")\n",
    "    start_station_id = int(parts[2])\n",
    "    \n",
    "    # Retrieve the starting station information from stations_df\n",
    "    starting_station = stations_df.loc[stations_df['id'] == start_station_id].iloc[0]\n",
    "    if start_station_id in scores_dict:\n",
    "        raise ValueError(f\"Duplicate starting station ID found: {start_station_id}\")\n",
    "    \n",
    "    # Prepare the merged DataFrame\n",
    "    merged = prepare_merged_df(travel_df, stations_df, starting_station, MIN_DISTANCE_KM, MAX_STATION_DISTANCE_KM)\n",
    "    \n",
    "    # Compute scores (use .copy() to avoid in-place modifications between functions)\n",
    "    simple_score = simple_efficiency_score(merged.copy())\n",
    "    distance_score = distance_adjusted_score(merged.copy())\n",
    "    exponential_score = exponential_decay_score(merged.copy())\n",
    "    normalized_score = normalized_composite_score(merged.copy(), stations_df, alpha=ALPHA, beta=BETA)\n",
    "    ratio_score = normalized_composite_ratio_score(merged.copy(), alpha=ALPHA, beta=BETA)\n",
    "    rank_score = normalized_composite_rank_score(merged.copy(), stations_df, alpha=ALPHA, beta=BETA)\n",
    "    \n",
    "    scores_dict[start_station_id] = {\n",
    "        'simple': simple_score,\n",
    "        'distance_adjusted': distance_score,\n",
    "        # 'exponential': exponential_score,\n",
    "        'normalized': normalized_score,\n",
    "        'normalized_ratio': ratio_score,\n",
    "        'normalized_rank': rank_score\n",
    "    }\n",
    "\n",
    "# Create a DataFrame from the scores dictionary.\n",
    "scores_df = pd.DataFrame.from_dict(scores_dict, orient='index')\n",
    "\n",
    "# Map station id to station name for readability.\n",
    "scores_df['station_name'] = scores_df.index.map(lambda sid: stations_df.loc[stations_df['id'] == sid, 'name'].values[0])\n",
    "scores_df = scores_df.set_index('station_name')\n",
    "\n",
    "# Print rankings for each metric\n",
    "print(\"Ranking by Simple Efficiency Score:\")\n",
    "print(scores_df.sort_values('simple', ascending=False)[['simple']])\n",
    "print(\"\\nRanking by Distance-Adjusted Efficiency Score:\")\n",
    "print(scores_df.sort_values('distance_adjusted', ascending=False)[['distance_adjusted']])\n",
    "# print(\"\\nRanking by Exponential Decay Score:\")\n",
    "# print(scores_df.sort_values('exponential', ascending=False)[['exponential']])\n",
    "print(\"\\nRanking by Normalized Composite Score:\")\n",
    "print(scores_df.sort_values('normalized', ascending=False)[['normalized']])\n",
    "print(\"\\nRanking by Normalized Composite Ratio Score (Country Population Proportion):\")\n",
    "print(scores_df.sort_values('normalized_ratio', ascending=False)[['normalized_ratio']])\n",
    "print(\"\\nRanking by Normalized Composite Rank Score (Country Population Rank):\")\n",
    "print(scores_df.sort_values('normalized_rank', ascending=False)[['normalized_rank']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```latex\n",
       "\\begin{table}\n",
       "\\caption{City Scores by Metric}\n",
       "\\label{tab:city_scores}\n",
       "\\begin{tabular}{llllll}\n",
       "\\toprule\n",
       " & simple & distance_adjusted & normalized & normalized_ratio & normalized_rank \\\\\n",
       "station_name &  &  &  &  &  \\\\\n",
       "\\midrule\n",
       "Bruxelles-Midi & \\textbf{69413}(1) & \\textbf{666023}(1) & \\textbf{0.14}(1) & \\textbf{9}(3) & 3.88 \\\\\n",
       "Paris Gare du Nord & \\textbf{60684}(2) & \\textbf{588433}(2) & \\textbf{0.12}(2) & \\textbf{12}(1) & \\textbf{4.47}(1) \\\\\n",
       "Amsterdam-Centraal & \\textbf{41413}(3) & \\textbf{480233}(3) & 0.11 & 9 & 3.34 \\\\\n",
       "Berlin Hbf & 29687 & 425822 & 0.12 & \\textbf{9}(2) & \\textbf{4.01}(3) \\\\\n",
       "Wien Hbf & 22280 & 411420 & 0.11 & 8.45 & 3.81 \\\\\n",
       "Luxembourg – Gare & 32628 & 381002 & 0.1 & 8.41 & 2.8 \\\\\n",
       "Budapest-Keleti & 13189 & 313982 & 0.1 & 7.03 & 3.43 \\\\\n",
       "Warszawa-Wschodnia & 11420 & 284589 & \\textbf{0.12}(3) & 9 & \\textbf{4.04}(2) \\\\\n",
       "Praha hl.n. & 22486 & 269545 & 0.09 & 7.75 & 2.87 \\\\\n",
       "Madrid Atocha & 13275 & 264138 & 0.09 & 8.47 & 3.46 \\\\\n",
       "Bratislava hl.st. & 14302 & 262004 & 0.1 & 7.77 & 3.25 \\\\\n",
       "København & 15969 & 228878 & 0.08 & 7.93 & 2.76 \\\\\n",
       "Stockholm Central & 7015 & 194842 & 0.08 & 7.63 & 2.85 \\\\\n",
       "Zagreb & 6451 & 151474 & 0.07 & 4.91 & 2.16 \\\\\n",
       "Roma Termini & 5306 & 108163 & 0.05 & 4.45 & 1.73 \\\\\n",
       "Vilnius & 2965 & 86707 & 0.03 & 5.19 & 1.95 \\\\\n",
       "Riga & 1709 & 59756 & 0.03 & 2.89 & 1.08 \\\\\n",
       "Lisboa Santa Apolónia & 1908 & 48504 & 0.03 & 2.79 & 1.21 \\\\\n",
       "Helsinki asema & 151 & 1152 & 0 & 0.53 & 0.02 \\\\\n",
       "București Nord & 12 & 111 & 0 & 0.44 & 0 \\\\\n",
       "Athens & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "Ljubljana & 0 & 0 & 0 & 0 & 0 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{table}\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def format_score(value, rank):\n",
    "    \"\"\"Format the score with bold and rank if in the top 3.\"\"\"\n",
    "    value = int(value) if value > 9 else round(value, 2)\n",
    "    if value < 0.01:\n",
    "        value = 0\n",
    "    if rank == 1:\n",
    "        return f\"\\\\textbf{{{value}}}(1)\"\n",
    "    elif rank == 2:\n",
    "        return f\"\\\\textbf{{{value}}}(2)\"\n",
    "    elif rank == 3:\n",
    "        return f\"\\\\textbf{{{value}}}(3)\"\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "# Round scores and determine rankings\n",
    "latex_df = scores_df.copy()\n",
    "for column in ['simple', 'distance_adjusted', 'normalized', 'normalized_ratio', 'normalized_rank']:\n",
    "    # Round values\n",
    "    latex_df[column] = latex_df[column]\n",
    "    # Rank values (descending order)\n",
    "    ranks = latex_df[column].rank(method='min', ascending=False).astype(int)\n",
    "    # Format scores with bold and rank for top 3\n",
    "    latex_df[column] = [format_score(value, rank) for value, rank in zip(latex_df[column], ranks)]\n",
    "\n",
    "# Add a column for the sum of scores\n",
    "latex_df['sum_of_scores'] = scores_df[['simple', 'distance_adjusted', 'normalized', 'normalized_ratio', 'normalized_rank']].sum(axis=1)\n",
    "\n",
    "# Sort by the sum of scores\n",
    "latex_df = latex_df.sort_values('sum_of_scores', ascending=False)\n",
    "\n",
    "# Replace underscores in station names with spaces for LaTeX compatibility\n",
    "latex_df.index = latex_df.index.str.replace('_', ' ')\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = latex_df.to_latex(escape=False, index=True, columns=[\n",
    "    'simple', 'distance_adjusted', 'normalized', 'normalized_ratio', 'normalized_rank'\n",
    "], caption=\"City Scores by Metric\", label=\"tab:city_scores\")\n",
    "\n",
    "# Save the LaTeX table to a file\n",
    "with open(\"city_scores_table.tex\", \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "# Display the LaTeX table\n",
    "display(Markdown(f\"```latex\\n{latex_table}\\n```\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
